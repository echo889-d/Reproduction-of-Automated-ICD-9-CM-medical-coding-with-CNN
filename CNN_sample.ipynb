{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_sample.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5OvzktKz0HQj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "import sklearn as sk\n",
        "import string\n",
        "import itertools\n",
        "from collections import Counter\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "import pickle\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn import preprocessing, metrics\n",
        "from keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Embedding, Activation,Input,concatenate,Flatten\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import multilabel_confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkkvxTQlVv4Y",
        "outputId": "27c063bc-982f-43ae-acfa-3e8e337afb14"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_full = pd.read_csv(\"drive/MyDrive/BD4H Project Folder/Tokenized.csv\",index_col=0)"
      ],
      "metadata": {
        "id": "6Yc6R1-j0USj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenized_full[:10000]\n",
        "tokenized = tokenized.reset_index(drop=True)\n",
        "tokenized"
      ],
      "metadata": {
        "id": "Gw8yn2VbDSzE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "9c2a5f3d-cc73-4fd9-f12b-943329c71301"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       HADM_ID                                               TEXT DESCRIPTION  \\\n",
              "0     121936.0  ['patient', 'test', 'information', 'indication...      Report   \n",
              "1     121936.0  ['patient', 'test', 'information', 'indication...      Report   \n",
              "2     121936.0  ['sinus', 'rhythm', 'frequent', 'atrial', 'pre...      Report   \n",
              "3     121936.0  ['rhythm', 'is', 'most', 'likely', 'sinus', 'r...      Report   \n",
              "4     121936.0  ['atrial', 'fibrillation', 'intraventricular',...      Report   \n",
              "...        ...                                                ...         ...   \n",
              "9995  152740.0  ['resp', 'care', 'received', 'from', 'or', 'an...      Report   \n",
              "9996  152740.0  ['or', 'today', 'for', 'debridement', 'of', 'l...      Report   \n",
              "9997  152740.0  ['npn', 'dd', 'dd', 'dd', 'dd', 'please', 'als...      Report   \n",
              "9998  152740.0  ['respiratory', 'care', 'patient', 'switched',...      Report   \n",
              "9999  152740.0  ['resp', 'care', 'pt', 'received', 'from', 'or...      Report   \n",
              "\n",
              "      SUBJECT_ID                                          ICD9_CODE  \\\n",
              "0          28063  ['42843', '41071', '5990', '4275', '5849', '50...   \n",
              "1          28063  ['42843', '41071', '5990', '4275', '5849', '50...   \n",
              "2          28063  ['42843', '41071', '5990', '4275', '5849', '50...   \n",
              "3          28063  ['42843', '41071', '5990', '4275', '5849', '50...   \n",
              "4          28063  ['42843', '41071', '5990', '4275', '5849', '50...   \n",
              "...          ...                                                ...   \n",
              "9995       31043  ['4414', '5570', '78551', '5849', '5770', '682...   \n",
              "9996       31043  ['4414', '5570', '78551', '5849', '5770', '682...   \n",
              "9997       31043  ['4414', '5570', '78551', '5849', '5770', '682...   \n",
              "9998       31043  ['4414', '5570', '78551', '5849', '5770', '682...   \n",
              "9999       31043  ['4414', '5570', '78551', '5849', '5770', '682...   \n",
              "\n",
              "                                      ICD9_CODE_primary  \n",
              "0     ['428', '410', '599', '427', '584', '507', '42...  \n",
              "1     ['428', '410', '599', '427', '584', '507', '42...  \n",
              "2     ['428', '410', '599', '427', '584', '507', '42...  \n",
              "3     ['428', '410', '599', '427', '584', '507', '42...  \n",
              "4     ['428', '410', '599', '427', '584', '507', '42...  \n",
              "...                                                 ...  \n",
              "9995  ['441', '557', '785', '584', '577', '682', '72...  \n",
              "9996  ['441', '557', '785', '584', '577', '682', '72...  \n",
              "9997  ['441', '557', '785', '584', '577', '682', '72...  \n",
              "9998  ['441', '557', '785', '584', '577', '682', '72...  \n",
              "9999  ['441', '557', '785', '584', '577', '682', '72...  \n",
              "\n",
              "[10000 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f312126-fd8c-4768-b8e7-821039301852\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>ICD9_CODE</th>\n",
              "      <th>ICD9_CODE_primary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>121936.0</td>\n",
              "      <td>['patient', 'test', 'information', 'indication...</td>\n",
              "      <td>Report</td>\n",
              "      <td>28063</td>\n",
              "      <td>['42843', '41071', '5990', '4275', '5849', '50...</td>\n",
              "      <td>['428', '410', '599', '427', '584', '507', '42...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>121936.0</td>\n",
              "      <td>['patient', 'test', 'information', 'indication...</td>\n",
              "      <td>Report</td>\n",
              "      <td>28063</td>\n",
              "      <td>['42843', '41071', '5990', '4275', '5849', '50...</td>\n",
              "      <td>['428', '410', '599', '427', '584', '507', '42...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>121936.0</td>\n",
              "      <td>['sinus', 'rhythm', 'frequent', 'atrial', 'pre...</td>\n",
              "      <td>Report</td>\n",
              "      <td>28063</td>\n",
              "      <td>['42843', '41071', '5990', '4275', '5849', '50...</td>\n",
              "      <td>['428', '410', '599', '427', '584', '507', '42...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>121936.0</td>\n",
              "      <td>['rhythm', 'is', 'most', 'likely', 'sinus', 'r...</td>\n",
              "      <td>Report</td>\n",
              "      <td>28063</td>\n",
              "      <td>['42843', '41071', '5990', '4275', '5849', '50...</td>\n",
              "      <td>['428', '410', '599', '427', '584', '507', '42...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>121936.0</td>\n",
              "      <td>['atrial', 'fibrillation', 'intraventricular',...</td>\n",
              "      <td>Report</td>\n",
              "      <td>28063</td>\n",
              "      <td>['42843', '41071', '5990', '4275', '5849', '50...</td>\n",
              "      <td>['428', '410', '599', '427', '584', '507', '42...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>152740.0</td>\n",
              "      <td>['resp', 'care', 'received', 'from', 'or', 'an...</td>\n",
              "      <td>Report</td>\n",
              "      <td>31043</td>\n",
              "      <td>['4414', '5570', '78551', '5849', '5770', '682...</td>\n",
              "      <td>['441', '557', '785', '584', '577', '682', '72...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>152740.0</td>\n",
              "      <td>['or', 'today', 'for', 'debridement', 'of', 'l...</td>\n",
              "      <td>Report</td>\n",
              "      <td>31043</td>\n",
              "      <td>['4414', '5570', '78551', '5849', '5770', '682...</td>\n",
              "      <td>['441', '557', '785', '584', '577', '682', '72...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>152740.0</td>\n",
              "      <td>['npn', 'dd', 'dd', 'dd', 'dd', 'please', 'als...</td>\n",
              "      <td>Report</td>\n",
              "      <td>31043</td>\n",
              "      <td>['4414', '5570', '78551', '5849', '5770', '682...</td>\n",
              "      <td>['441', '557', '785', '584', '577', '682', '72...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>152740.0</td>\n",
              "      <td>['respiratory', 'care', 'patient', 'switched',...</td>\n",
              "      <td>Report</td>\n",
              "      <td>31043</td>\n",
              "      <td>['4414', '5570', '78551', '5849', '5770', '682...</td>\n",
              "      <td>['441', '557', '785', '584', '577', '682', '72...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>152740.0</td>\n",
              "      <td>['resp', 'care', 'pt', 'received', 'from', 'or...</td>\n",
              "      <td>Report</td>\n",
              "      <td>31043</td>\n",
              "      <td>['4414', '5570', '78551', '5849', '5770', '682...</td>\n",
              "      <td>['441', '557', '785', '584', '577', '682', '72...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f312126-fd8c-4768-b8e7-821039301852')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f312126-fd8c-4768-b8e7-821039301852 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f312126-fd8c-4768-b8e7-821039301852');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized[\"TEXT\"] = tokenized[\"TEXT\"].apply(literal_eval)\n",
        "tokenized[\"ICD9_CODE\"] = tokenized[\"ICD9_CODE\"].apply(literal_eval)\n",
        "tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "9HuPB3WyL5dh",
        "outputId": "0469a71c-0e54-44e2-d6a8-6318cfe42455"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       HADM_ID                                               TEXT DESCRIPTION  \\\n",
              "0     121936.0  [patient, test, information, indication, aorti...      Report   \n",
              "1     121936.0  [patient, test, information, indication, aorti...      Report   \n",
              "2     121936.0  [sinus, rhythm, frequent, atrial, premature, b...      Report   \n",
              "3     121936.0  [rhythm, is, most, likely, sinus, rhythm, with...      Report   \n",
              "4     121936.0  [atrial, fibrillation, intraventricular, condu...      Report   \n",
              "...        ...                                                ...         ...   \n",
              "9995  152740.0  [resp, care, received, from, or, and, placed, ...      Report   \n",
              "9996  152740.0  [or, today, for, debridement, of, left, flank,...      Report   \n",
              "9997  152740.0  [npn, dd, dd, dd, dd, please, also, see, carev...      Report   \n",
              "9998  152740.0  [respiratory, care, patient, switched, to, cpa...      Report   \n",
              "9999  152740.0  [resp, care, pt, received, from, or, intubated...      Report   \n",
              "\n",
              "      SUBJECT_ID                                          ICD9_CODE  \\\n",
              "0          28063  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
              "1          28063  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
              "2          28063  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
              "3          28063  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
              "4          28063  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
              "...          ...                                                ...   \n",
              "9995       31043  [4414, 5570, 78551, 5849, 5770, 6822, 72973, 9...   \n",
              "9996       31043  [4414, 5570, 78551, 5849, 5770, 6822, 72973, 9...   \n",
              "9997       31043  [4414, 5570, 78551, 5849, 5770, 6822, 72973, 9...   \n",
              "9998       31043  [4414, 5570, 78551, 5849, 5770, 6822, 72973, 9...   \n",
              "9999       31043  [4414, 5570, 78551, 5849, 5770, 6822, 72973, 9...   \n",
              "\n",
              "                                      ICD9_CODE_primary  \n",
              "0     ['428', '410', '599', '427', '584', '507', '42...  \n",
              "1     ['428', '410', '599', '427', '584', '507', '42...  \n",
              "2     ['428', '410', '599', '427', '584', '507', '42...  \n",
              "3     ['428', '410', '599', '427', '584', '507', '42...  \n",
              "4     ['428', '410', '599', '427', '584', '507', '42...  \n",
              "...                                                 ...  \n",
              "9995  ['441', '557', '785', '584', '577', '682', '72...  \n",
              "9996  ['441', '557', '785', '584', '577', '682', '72...  \n",
              "9997  ['441', '557', '785', '584', '577', '682', '72...  \n",
              "9998  ['441', '557', '785', '584', '577', '682', '72...  \n",
              "9999  ['441', '557', '785', '584', '577', '682', '72...  \n",
              "\n",
              "[10000 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7f962bc-4350-48fd-907c-b8ac1634760e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>ICD9_CODE</th>\n",
              "      <th>ICD9_CODE_primary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>121936.0</td>\n",
              "      <td>[patient, test, information, indication, aorti...</td>\n",
              "      <td>Report</td>\n",
              "      <td>28063</td>\n",
              "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
              "      <td>['428', '410', '599', '427', '584', '507', '42...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>121936.0</td>\n",
              "      <td>[patient, test, information, indication, aorti...</td>\n",
              "      <td>Report</td>\n",
              "      <td>28063</td>\n",
              "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
              "      <td>['428', '410', '599', '427', '584', '507', '42...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>121936.0</td>\n",
              "      <td>[sinus, rhythm, frequent, atrial, premature, b...</td>\n",
              "      <td>Report</td>\n",
              "      <td>28063</td>\n",
              "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
              "      <td>['428', '410', '599', '427', '584', '507', '42...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>121936.0</td>\n",
              "      <td>[rhythm, is, most, likely, sinus, rhythm, with...</td>\n",
              "      <td>Report</td>\n",
              "      <td>28063</td>\n",
              "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
              "      <td>['428', '410', '599', '427', '584', '507', '42...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>121936.0</td>\n",
              "      <td>[atrial, fibrillation, intraventricular, condu...</td>\n",
              "      <td>Report</td>\n",
              "      <td>28063</td>\n",
              "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
              "      <td>['428', '410', '599', '427', '584', '507', '42...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>152740.0</td>\n",
              "      <td>[resp, care, received, from, or, and, placed, ...</td>\n",
              "      <td>Report</td>\n",
              "      <td>31043</td>\n",
              "      <td>[4414, 5570, 78551, 5849, 5770, 6822, 72973, 9...</td>\n",
              "      <td>['441', '557', '785', '584', '577', '682', '72...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>152740.0</td>\n",
              "      <td>[or, today, for, debridement, of, left, flank,...</td>\n",
              "      <td>Report</td>\n",
              "      <td>31043</td>\n",
              "      <td>[4414, 5570, 78551, 5849, 5770, 6822, 72973, 9...</td>\n",
              "      <td>['441', '557', '785', '584', '577', '682', '72...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>152740.0</td>\n",
              "      <td>[npn, dd, dd, dd, dd, please, also, see, carev...</td>\n",
              "      <td>Report</td>\n",
              "      <td>31043</td>\n",
              "      <td>[4414, 5570, 78551, 5849, 5770, 6822, 72973, 9...</td>\n",
              "      <td>['441', '557', '785', '584', '577', '682', '72...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>152740.0</td>\n",
              "      <td>[respiratory, care, patient, switched, to, cpa...</td>\n",
              "      <td>Report</td>\n",
              "      <td>31043</td>\n",
              "      <td>[4414, 5570, 78551, 5849, 5770, 6822, 72973, 9...</td>\n",
              "      <td>['441', '557', '785', '584', '577', '682', '72...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>152740.0</td>\n",
              "      <td>[resp, care, pt, received, from, or, intubated...</td>\n",
              "      <td>Report</td>\n",
              "      <td>31043</td>\n",
              "      <td>[4414, 5570, 78551, 5849, 5770, 6822, 72973, 9...</td>\n",
              "      <td>['441', '557', '785', '584', '577', '682', '72...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7f962bc-4350-48fd-907c-b8ac1634760e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7f962bc-4350-48fd-907c-b8ac1634760e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7f962bc-4350-48fd-907c-b8ac1634760e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_icd9(x):\n",
        "    converted_code = []\n",
        "    for code in x:\n",
        "        icd9_str = str(code)\n",
        "        if icd9_str.startswith(\"E\"):\n",
        "            converted = icd9_str[:4]\n",
        "        else:\n",
        "            converted = icd9_str[:3]\n",
        "        converted_code.append(converted)\n",
        "    return converted_code\n",
        "tokenized[\"ICD9_CODE_primary\"] = tokenized[\"ICD9_CODE\"].apply(lambda x: convert_icd9(x))"
      ],
      "metadata": {
        "id": "PKgT82clZa6y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(tokenized[\"ICD9_CODE_primary\"])\n",
        "y = pd.DataFrame(y)\n",
        "print(y.shape) #full: (399623, 808)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45pjWXPkZ46D",
        "outputId": "1b7a59eb-7fa1-4133-8ae6-e03fde2af5fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 363)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlb2 = preprocessing.MultiLabelBinarizer()\n",
        "y_regular = mlb2.fit_transform(tokenized[\"ICD9_CODE\"])\n",
        "y_regular = pd.DataFrame(y_regular)\n",
        "print(y_regular.shape) #full: (399623, 808)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKkKd4hxs0GT",
        "outputId": "1e1295bc-8f0e-4168-e64a-d178b9d0f106"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 936)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#metrics.precision_score(y_test, yhat_cnn, average='weighted')\n",
        "#metrics.recall_score(y_test, yhat_cnn, average='weighted')\n",
        "#metrics.f1_score(y_test, yhat_cnn, average='weighted')"
      ],
      "metadata": {
        "id": "-65K_YlnSKvC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(y_true, y_pred):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    f1_list = []\n",
        "    mcm = multilabel_confusion_matrix(y_true, y_pred)\n",
        "    for i in range(len(mcm)):\n",
        "        tn, fp, fn, tp = mcm[i].ravel()\n",
        "        if tp == 0:\n",
        "            precision = 0\n",
        "            recall = 0\n",
        "            f1 = 0\n",
        "        else:\n",
        "            precision = tp/ (tp+fp)\n",
        "            recall = tp/(fn)\n",
        "            f1 = 2*precision*recall/(precision+recall)\n",
        "        precision_list.append(precision) \n",
        "        recall_list.append(recall)\n",
        "        f1_list.append(f1)\n",
        "    return np.mean(precision_list),np.mean(recall_list),np.mean(f1_list)"
      ],
      "metadata": {
        "id": "6SXNPohgtN3j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_based_macro_precision(y_true, y_pred):\n",
        "\t\n",
        "\t# axis = 0 computes true positive along columns i.e labels\n",
        "\tl_prec_num = np.sum(np.logical_and(y_true, y_pred), axis = 0)\n",
        "\n",
        "\t# axis = computes true_positive + false positive along columns i.e labels\n",
        "\tl_prec_den = np.sum(y_pred, axis = 0)\n",
        "\n",
        "\t# compute precision per class/label\n",
        "\tl_prec_per_class = l_prec_num/l_prec_den\n",
        "\n",
        "\t# macro precision = average of precsion across labels. \n",
        "\tl_prec = np.mean(l_prec_per_class)\n",
        "\treturn l_prec\n"
      ],
      "metadata": {
        "id": "FsT06JcHuWiQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_based_macro_recall(y_true, y_pred):\n",
        "    \n",
        "    # compute true positive along axis = 0 i.e labels\n",
        "    #l_recall_num = np.sum(np.logical_and(y_true, y_pred), axis = 0)\n",
        "\n",
        "    # compute true positive + false negatives along axis = 0 i.e columns\n",
        "    #l_recall_den = np.sum(np.logical_and(y_true, y_pred), axis = 0)\n",
        "    #l_recall_den = np.sum(y_true, axis = 0)\n",
        "\n",
        "    # compute recall per class/label\n",
        "    #l_recall_per_class = l_recall_num/l_recall_den\n",
        "\n",
        "    tp = np.sum(np.logical_and(y_true, y_pred))\n",
        "    \n",
        "    # compute false negatives (Missed Labels) across training examples and labels\n",
        "    fn = np.sum(np.logical_and(y_true, np.logical_not(y_pred)))\n",
        "    \n",
        "    fp = np.sum(np.logical_and(np.logical_not(y_true), y_pred))\n",
        "\n",
        "    # compute macro averaged recall i.e recall averaged across labels. \n",
        "    #l_recall = np.mean(l_recall_per_class)\n",
        "    \n",
        "    return np.mean(tp/(tp+fn))"
      ],
      "metadata": {
        "id": "ZpaYPinHvUL9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_evaluation_score(y_true, y_pred):\n",
        "   \n",
        "    # compute true positives across training examples and labels\n",
        "    tp = np.sum(np.logical_and(y_true, y_pred))\n",
        "    \n",
        "    # compute false negatives (Missed Labels) across training examples and labels\n",
        "    fn = np.sum(np.logical_and(y_true, np.logical_not(y_pred)))\n",
        "    \n",
        "    fp = np.sum(np.logical_and(np.logical_not(y_true), y_pred))\n",
        "\n",
        "    # compute False Positive across training examples and labels.\n",
        "    f1 = 2*tp / (2* tp + fp + fn)\n",
        "    \n",
        "    return np.mean(f1)"
      ],
      "metadata": {
        "id": "dCUgtktkv41b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score(precision,recall):\n",
        "    return 2*precision*recall/(precision+recall)"
      ],
      "metadata": {
        "id": "5I4RrddRUtH4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_w2v_model(x_train):\n",
        "    #w2v_model = Word2Vec.load(\"drive/MyDrive/BD4H Project Folder/word2vec.model\")\n",
        "    w2v_model = Word2Vec(x_train, size=300)\n",
        "    #w2v_model.save(\"word2vec_test.model\")\n",
        "    #print(w2v_model)\n",
        "    return w2v_model"
      ],
      "metadata": {
        "id": "LvHNPYcvZ49a"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sequence(w2v_model,x_train,x_val,x_test):\n",
        "    num_unique_tokens = len(w2v_model.wv.vocab)\n",
        "    token = Tokenizer(num_unique_tokens)\n",
        "    token.fit_on_texts(x_train)\n",
        "    train_text = token.texts_to_sequences(x_train)\n",
        "    x_train_seq = pad_sequences(train_text)\n",
        "    print(x_train_seq.shape) \n",
        "\n",
        "    sequences_val = token.texts_to_sequences(x_val)\n",
        "    x_val_seq = pad_sequences(sequences_val, maxlen=x_train_seq.shape[1]) \n",
        "    print(x_val_seq.shape)\n",
        "\n",
        "    sequences_test = token.texts_to_sequences(x_test)\n",
        "    x_test_seq = pad_sequences(sequences_test, maxlen=x_train_seq.shape[1]) \n",
        "    print(x_test_seq.shape)\n",
        "\n",
        "    return x_train_seq,x_val_seq,x_test_seq"
      ],
      "metadata": {
        "id": "4ndDZo8EZ3jw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_embedding_vector(w2v_model):\n",
        "\n",
        "    num_unique_tokens = len(w2v_model.wv.vocab)\n",
        "    token = Tokenizer(num_unique_tokens)\n",
        "    embeddings_index = {}\n",
        "    for w in w2v_model.wv.vocab.keys():\n",
        "        embeddings_index[w] = w2v_model.wv[w]\n",
        "\n",
        "    num_words = num_unique_tokens\n",
        "    embedding_matrix = np.zeros((num_words, 300))\n",
        "    for word, i in token.word_index.items():\n",
        "        if i >= num_words:\n",
        "            continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "qF2W9JElickG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CNN_base(x_train_seq,y_train,x_val_seq,y_val,x_test_seq,y_test,num_unique_tokens):\n",
        "    report_input = Input(shape=(x_train_seq.shape[1],), dtype='int32')\n",
        "\n",
        "    report_encoder = Embedding(num_unique_tokens, 300, weights=[embedding_matrix], input_length=x_train_seq.shape[1], trainable=False)(report_input)\n",
        "    bigram_branch = Conv1D(filters=250, kernel_size=3, padding='valid', activation='relu', strides=1)(report_encoder)\n",
        "    bigram_branch = GlobalMaxPooling1D()(bigram_branch)\n",
        "\n",
        "    #trigram_branch = Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
        "    #trigram_branch = GlobalMaxPooling1D()(trigram_branch)\n",
        "    #fourgram_branch = Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
        "    #fourgram_branch = GlobalMaxPooling1D()(fourgram_branch)\n",
        "    #merged = concatenate([bigram_branch, trigram_branch, fourgram_branch], axis=1)\n",
        "\n",
        "    merged = Dense(y_train.shape[1])(bigram_branch)\n",
        "    #merged = Dropout(0.2)(merged)\n",
        "    #merged = Dense(1)(merged)\n",
        "    output = Activation('relu')(merged)\n",
        "\n",
        "    model = Model(inputs=[report_input], outputs=[output])\n",
        "\n",
        "    #model.compile(optimizer=adam, loss='binary_crossentropy', vmetrics=['accuracy'])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "    #model.summary()\n",
        "\n",
        "    callbacks = [EarlyStopping(monitor='val_loss')]\n",
        "    model.fit(x_train_seq, y_train, batch_size=32, epochs=5, validation_data=(x_val_seq, y_val), callbacks = callbacks)\n",
        "    #model.evaluate(x=x_val_seq, y=y_val)\n",
        "\n",
        "    yhat_cnn = model.predict(x_test_seq)\n",
        "    #model.evaluate(x=x_test_seq, y=y_test)\n",
        "    yhat_cnn = model.predict(x_test_seq)\n",
        "    yhat_cnn[yhat_cnn>0.5] = 1\n",
        "    yhat_cnn[yhat_cnn<=0.5] = 0\n",
        "    yhat_cnn = pd.DataFrame(yhat_cnn,dtype=int)\n",
        "\n",
        "    precision = label_based_macro_precision(y_test, yhat_cnn) \n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = label_based_macro_recall(y_test, yhat_cnn) \n",
        "    # f1: 2 tp / (2 tp + fp + fn)\n",
        "    f1 = f1_evaluation_score(y_test, yhat_cnn)\n",
        "    \n",
        "    return  precision, recall, f1"
      ],
      "metadata": {
        "id": "giJhzcBKkvjx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CNN_base_test(x_train_seq,y_train,x_val_seq,y_val,x_test_seq,y_test,num_unique_tokens):\n",
        "    report_input = Input(shape=(x_train_seq.shape[1],), dtype='int32')\n",
        "\n",
        "    report_encoder = Embedding(num_unique_tokens, 300, input_length=x_train_seq.shape[1], trainable=True)(report_input)\n",
        "    bigram_branch = Conv1D(filters=250, kernel_size=3, activation='relu',padding='valid',strides=1)(report_encoder)\n",
        "    bigram_branch = GlobalMaxPooling1D()(bigram_branch)\n",
        "\n",
        "    merged = Dense(y_train.shape[1])(bigram_branch)\n",
        "\n",
        "    output = Activation('sigmoid')(merged)\n",
        "    #trigram_branch = Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
        "    #trigram_branch = GlobalMaxPooling1D()(trigram_branch)\n",
        "    #fourgram_branch = Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
        "    #fourgram_branch = GlobalMaxPooling1D()(fourgram_branch)\n",
        "    #merged = concatenate([bigram_branch, trigram_branch, fourgram_branch], axis=1)\n",
        "\n",
        "    #merged = Dense(y_train.shape[1])(bigram_branch)\n",
        "    #merged = Dropout(0.2)(merged)\n",
        "    #merged = Dense(1)(merged)\n",
        "\n",
        "    model = Model(inputs=[report_input], outputs=[output])\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), loss=tf.keras.losses.BinaryCrossentropy())\n",
        "    #model.summary()\n",
        "    \n",
        "    callbacks = [EarlyStopping(min_delta=0.0001,patience=2)]\n",
        "    model.fit(x_train_seq, y_train, batch_size=32, epochs=3, validation_data=(x_val_seq, y_val),callbacks=callbacks)\n",
        "    #model.evaluate(x=x_val_seq, y=y_val)\n",
        "    #_, train_acc = model.evaluate(x_train_seq, y_train)\n",
        "    #_, val_acc = model.evaluate(x_val_seq, y_val)\n",
        "    #pyplot.plot(history.history['loss'], label='train')\n",
        "    #pyplot.plot(history.history['val_loss'], label='validation')\n",
        "    #pyplot.legend()\n",
        "    #pyplot.show()\n",
        "\n",
        "    #model.evaluate(x=x_test_seq, y=y_test)\n",
        "    yhat_cnn = model.predict(x_test_seq)\n",
        "    yhat_cnn[yhat_cnn>0.5] = 1\n",
        "    yhat_cnn[yhat_cnn<=0.5] = 0\n",
        "    yhat_cnn = pd.DataFrame(yhat_cnn,dtype=int)\n",
        "\n",
        "    precision = label_based_macro_precision(y_test, yhat_cnn) \n",
        "    # recall: tp / (tp + fn)\n",
        "    recall = label_based_macro_recall(y_test, yhat_cnn) \n",
        "    # f1: 2 tp / (2 tp + fp + fn)\n",
        "    #f1 = f1_evaluation_score(y_test, yhat_cnn)\n",
        "    f1 = f1_score(precision,recall)\n",
        "    #precision2, recall2, f12 = eval(y_test, yhat_cnn)\n",
        "    #precision = metrics.precision_score(y_test, yhat_cnn, average=None)\n",
        "    #recall = metrics.recall_score(y_test, yhat_cnn, average=None)\n",
        "    #f1 = metrics.f1_score(y_test, yhat_cnn, average=None)\n",
        "    return  precision, recall, f1"
      ],
      "metadata": {
        "id": "SzyBzqt09Dul"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits = 5, shuffle = True, random_state = 2)\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "\n",
        "for train_index, test_index in kf.split(tokenized):\n",
        "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    x_train, x_test = tokenized[\"TEXT\"].iloc[train_index], tokenized[\"TEXT\"].iloc[test_index]\n",
        "    y_train,y_test = y.iloc[train_index],y.iloc[test_index]\n",
        "    x_val = x_train.sample(frac=0.1,random_state=42)\n",
        "    y_val = y_train.sample(frac=0.1,random_state=42)\n",
        "\n",
        "    w2v_model = build_w2v_model(x_train)\n",
        "    num_unique_tokens = len(w2v_model.wv.vocab)\n",
        "    x_train_seq,x_val_seq,x_test_seq = get_sequence(w2v_model,x_train,x_val,x_test)\n",
        "    embedding_matrix = build_embedding_vector(w2v_model)\n",
        "\n",
        "    precision, recall, f1 = CNN_base_test(x_train_seq,y_train,x_val_seq,y_val,x_test_seq,y_test,num_unique_tokens)\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    f1_list.append(f1)\n",
        "    \n",
        "    \n",
        "\n",
        "print(np.mean(precision_list))\n",
        "print(np.mean(recall_list))\n",
        "print(np.mean(f1_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYqZOSXbdOGs",
        "outputId": "fda754c7-18f3-4155-b1ac-463e617030b3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 2174)\n",
            "(800, 2174)\n",
            "(2000, 2174)\n",
            "Epoch 1/3\n",
            "250/250 [==============================] - 536s 2s/step - loss: 0.1100 - val_loss: 0.0838\n",
            "Epoch 2/3\n",
            "250/250 [==============================] - 469s 2s/step - loss: 0.0789 - val_loss: 0.0691\n",
            "Epoch 3/3\n",
            "250/250 [==============================] - 461s 2s/step - loss: 0.0699 - val_loss: 0.0651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 2174)\n",
            "(800, 2174)\n",
            "(2000, 2174)\n",
            "Epoch 1/3\n",
            "250/250 [==============================] - 466s 2s/step - loss: 0.1105 - val_loss: 0.0822\n",
            "Epoch 2/3\n",
            "250/250 [==============================] - 465s 2s/step - loss: 0.0787 - val_loss: 0.0698\n",
            "Epoch 3/3\n",
            "250/250 [==============================] - 461s 2s/step - loss: 0.0691 - val_loss: 0.0623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 2177)\n",
            "(800, 2177)\n",
            "(2000, 2177)\n",
            "Epoch 1/3\n",
            "250/250 [==============================] - 463s 2s/step - loss: 0.1110 - val_loss: 0.0802\n",
            "Epoch 2/3\n",
            "250/250 [==============================] - 460s 2s/step - loss: 0.0790 - val_loss: 0.0697\n",
            "Epoch 3/3\n",
            "250/250 [==============================] - 461s 2s/step - loss: 0.0702 - val_loss: 0.0643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 2177)\n",
            "(800, 2177)\n",
            "(2000, 2177)\n",
            "Epoch 1/3\n",
            "250/250 [==============================] - 459s 2s/step - loss: 0.1103 - val_loss: 0.0770\n",
            "Epoch 2/3\n",
            "250/250 [==============================] - 461s 2s/step - loss: 0.0780 - val_loss: 0.0672\n",
            "Epoch 3/3\n",
            "250/250 [==============================] - 461s 2s/step - loss: 0.0691 - val_loss: 0.0625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 2174)\n",
            "(800, 2174)\n",
            "(2000, 2174)\n",
            "Epoch 1/3\n",
            "250/250 [==============================] - 461s 2s/step - loss: 0.1102 - val_loss: 0.0882\n",
            "Epoch 2/3\n",
            "250/250 [==============================] - 457s 2s/step - loss: 0.0788 - val_loss: 0.0755\n",
            "Epoch 3/3\n",
            "250/250 [==============================] - 458s 2s/step - loss: 0.0692 - val_loss: 0.0681\n",
            "0.7826206422020715\n",
            "0.3767451106278674\n",
            "0.5078554546630053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits = 5, shuffle = True, random_state = 2)\n",
        "precision_list_re = []\n",
        "recall_list_re = []\n",
        "f1_list_re = []\n",
        "\n",
        "for train_index, test_index in kf.split(tokenized):\n",
        "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    x_train, x_test = tokenized[\"TEXT\"].iloc[train_index], tokenized[\"TEXT\"].iloc[test_index]\n",
        "    y_train_regular,y_test_regular = y_regular.iloc[train_index],y_regular.iloc[test_index]\n",
        "    x_val = x_train.sample(frac=0.1,random_state=42)\n",
        "    y_val_regular = y_train_regular.sample(frac=0.1,random_state=42)\n",
        "\n",
        "    w2v_model = build_w2v_model(x_train)\n",
        "    num_unique_tokens = len(w2v_model.wv.vocab)\n",
        "    x_train_seq,x_val_seq,x_test_seq = get_sequence(w2v_model,x_train,x_val,x_test)\n",
        "    embedding_matrix = build_embedding_vector(w2v_model)\n",
        "\n",
        "    precision_regular, recall_regular, f1_regular = CNN_base_test(x_train_seq,y_train_regular,x_val_seq,y_val_regular,x_test_seq,y_test_regular,num_unique_tokens)\n",
        "    precision_list_re.append(precision_regular)\n",
        "    recall_list_re.append(recall_regular)\n",
        "    f1_list_re.append(f1_regular)\n",
        "    \n",
        "    \n",
        "\n",
        "print(np.mean(precision_list))\n",
        "print(np.mean(recall_list))\n",
        "print(np.mean(f1_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVVVifHa9KMu",
        "outputId": "95f0e42c-8678-4be1-82bd-0c0a97029424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 2174)\n",
            "(800, 2174)\n",
            "(2000, 2174)\n",
            "Epoch 1/3\n",
            "250/250 [==============================] - 465s 2s/step - loss: 0.0698 - val_loss: 0.0482\n",
            "Epoch 2/3\n",
            "250/250 [==============================] - 459s 2s/step - loss: 0.0457 - val_loss: 0.0439\n",
            "Epoch 3/3\n",
            "250/250 [==============================] - 452s 2s/step - loss: 0.0404 - val_loss: 0.0361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
            "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 2174)\n",
            "(800, 2174)\n",
            "(2000, 2174)\n",
            "Epoch 1/3\n",
            "250/250 [==============================] - 460s 2s/step - loss: 0.0699 - val_loss: 0.0493\n",
            "Epoch 2/3\n",
            "128/250 [==============>...............] - ETA: 3:39 - loss: 0.0479"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.kaggle.com/code/marijakekic/cnn-in-keras-with-pretrained-word2vec-weights/notebook\n",
        "#https://pianalytix.com/multi-label-text-classification/\n",
        "#https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-11-cnn-word2vec-41f5e28eda74\n",
        "#https://medium.datadriveninvestor.com/a-survey-of-evaluation-metrics-for-multilabel-classification-bb16e8cd41cd"
      ],
      "metadata": {
        "id": "d3mjpfktBkqV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}