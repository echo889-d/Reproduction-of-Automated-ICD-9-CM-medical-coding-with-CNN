{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24fd164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import string\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from Levenshtein import distance as lev\n",
    "from ast import literal_eval\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "import fasttext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48383e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balle\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "noteEvents=pd.read_csv(\"mimic-iii-clinical-database-1.4/NOTEEVENTS.csv\")\n",
    "diagnosis = pd.read_csv(\"mimic-iii-clinical-database-1.4/DIAGNOSES_ICD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10259b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Case Management ',\n",
       " 'Consult',\n",
       " 'Discharge summary',\n",
       " 'ECG',\n",
       " 'Echo',\n",
       " 'General',\n",
       " 'Nursing',\n",
       " 'Nursing/other',\n",
       " 'Nutrition',\n",
       " 'Pharmacy',\n",
       " 'Physician ',\n",
       " 'Radiology',\n",
       " 'Rehab Services',\n",
       " 'Respiratory ',\n",
       " 'Social Work'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories=set(noteEvents[\"CATEGORY\"].tolist())\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa553c5",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0266f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "noteEvents=noteEvents[[\"HADM_ID\",\"TEXT\",\"DESCRIPTION\",\"CATEGORY\"]]\n",
    "diagnosis = diagnosis[[\"HADM_ID\",\"SUBJECT_ID\",\"ICD9_CODE\"]]\n",
    "\n",
    "def exclude_procedure_code(x):\n",
    "    if str(x).startswith(\"0\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "#Group Diagnosis into 1 list per admission\n",
    "diagnosis=diagnosis[diagnosis[\"ICD9_CODE\"].apply(lambda x: exclude_procedure_code(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9d4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_icd9(x):\n",
    "    converted_code = []\n",
    "    for code in x:\n",
    "        icd9_str = str(code)\n",
    "        if icd9_str.startswith(\"E\"):\n",
    "            converted = icd9_str[:4]\n",
    "        else:\n",
    "            converted = icd9_str[:3]\n",
    "        converted_code.append(converted)\n",
    "    return converted_code\n",
    "\n",
    "def checkdiagnosis(x):\n",
    "    for code in x:\n",
    "        if str(code)[0:3]==\"250\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def exclude_procedure_code(x):\n",
    "    included_code = []\n",
    "    for code in x:\n",
    "        icd9_str = str(code)\n",
    "        if icd9_str.startswith(\"0\"):\n",
    "            pass\n",
    "        else:\n",
    "            included_code.append(code)\n",
    "    return included_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f95df955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>163353</td>\n",
       "      <td>[V3001, V053, V290]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>[78559, 5849, 4275, 41071, 4280, 6826, 4254, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>[1363, 7994, 2763, 7907, 5715, V090, E9317]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>178980</td>\n",
       "      <td>[V3000, V053, V290]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>107064</td>\n",
       "      <td>[40391, 4440, 9972, 2766, 2767, 2859, 2753, V1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  HADM_ID                                          ICD9_CODE\n",
       "0           2   163353                                [V3001, V053, V290]\n",
       "1           3   145834  [78559, 5849, 4275, 41071, 4280, 6826, 4254, 2...\n",
       "2           4   185777        [1363, 7994, 2763, 7907, 5715, V090, E9317]\n",
       "3           5   178980                                [V3000, V053, V290]\n",
       "4           6   107064  [40391, 4440, 9972, 2766, 2767, 2859, 2753, V1..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosisGrouped = diagnosis.groupby([\"SUBJECT_ID\",\"HADM_ID\"])[\"ICD9_CODE\"].apply(list).reset_index()\n",
    "diagnosisGrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c57a04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balle\\AppData\\Local\\Temp/ipykernel_8240/642132842.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  admissionswithDiabetes[\"ICD9_CODE_primary\"] = admissionswithDiabetes[\"ICD9_CODE\"].apply(lambda x: convert_icd9(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>ICD9_CODE_primary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>143045</td>\n",
       "      <td>[41401, 4111, 25000, 4019, 2720]</td>\n",
       "      <td>[414, 411, 250, 401, 272]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>188822</td>\n",
       "      <td>[25080, 78039, 29633, V5867, E9323, V5869, 478...</td>\n",
       "      <td>[250, 780, 296, V58, E932, V58, 478, 780, 783,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>157681</td>\n",
       "      <td>[41401, 4111, 25000, 2724, 4019]</td>\n",
       "      <td>[414, 411, 250, 272, 401]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21</td>\n",
       "      <td>109451</td>\n",
       "      <td>[41071, 78551, 5781, 5849, 40391, 4280, 4592, ...</td>\n",
       "      <td>[410, 785, 578, 584, 403, 428, 459, 507, 427, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>111970</td>\n",
       "      <td>[78552, 40391, 42731, 70709, 5119, 6823, 99859...</td>\n",
       "      <td>[785, 403, 427, 707, 511, 682, 998, 572, 995, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SUBJECT_ID  HADM_ID                                          ICD9_CODE  \\\n",
       "11          13   143045                   [41401, 4111, 25000, 4019, 2720]   \n",
       "15          18   188822  [25080, 78039, 29633, V5867, E9323, V5869, 478...   \n",
       "17          20   157681                   [41401, 4111, 25000, 2724, 4019]   \n",
       "18          21   109451  [41071, 78551, 5781, 5849, 40391, 4280, 4592, ...   \n",
       "19          21   111970  [78552, 40391, 42731, 70709, 5119, 6823, 99859...   \n",
       "\n",
       "                                    ICD9_CODE_primary  \n",
       "11                          [414, 411, 250, 401, 272]  \n",
       "15  [250, 780, 296, V58, E932, V58, 478, 780, 783,...  \n",
       "17                          [414, 411, 250, 272, 401]  \n",
       "18  [410, 785, 578, 584, 403, 428, 459, 507, 427, ...  \n",
       "19  [785, 403, 427, 707, 511, 682, 998, 572, 995, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosisGrouped[\"ICD9_CODE\"] = diagnosisGrouped[\"ICD9_CODE\"].apply(lambda x: exclude_procedure_code(x))\n",
    "admissionswithDiabetes = diagnosisGrouped[diagnosisGrouped[\"ICD9_CODE\"].apply(lambda x: checkdiagnosis(x))]\n",
    "admissionswithDiabetes[\"ICD9_CODE_primary\"] = admissionswithDiabetes[\"ICD9_CODE\"].apply(lambda x: convert_icd9(x))\n",
    "admissionswithDiabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b6363ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406203, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>ICD9_CODE_primary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121936.0</td>\n",
       "      <td>Admission Date:  [**2125-2-9**]              D...</td>\n",
       "      <td>Report</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>28063</td>\n",
       "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
       "      <td>[428, 410, 599, 427, 584, 507, 428, 272, 401, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121936.0</td>\n",
       "      <td>PATIENT/TEST INFORMATION:\\nIndication: Aortic ...</td>\n",
       "      <td>Report</td>\n",
       "      <td>Echo</td>\n",
       "      <td>28063</td>\n",
       "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
       "      <td>[428, 410, 599, 427, 584, 507, 428, 272, 401, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121936.0</td>\n",
       "      <td>PATIENT/TEST INFORMATION:\\nIndication:  Aortic...</td>\n",
       "      <td>Report</td>\n",
       "      <td>Echo</td>\n",
       "      <td>28063</td>\n",
       "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
       "      <td>[428, 410, 599, 427, 584, 507, 428, 272, 401, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121936.0</td>\n",
       "      <td>Sinus rhythm.  Frequent atrial premature beats...</td>\n",
       "      <td>Report</td>\n",
       "      <td>ECG</td>\n",
       "      <td>28063</td>\n",
       "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
       "      <td>[428, 410, 599, 427, 584, 507, 428, 272, 401, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121936.0</td>\n",
       "      <td>Rhythm is most likely sinus rhythm with freque...</td>\n",
       "      <td>Report</td>\n",
       "      <td>ECG</td>\n",
       "      <td>28063</td>\n",
       "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
       "      <td>[428, 410, 599, 427, 584, 507, 428, 272, 401, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HADM_ID                                               TEXT DESCRIPTION  \\\n",
       "0  121936.0  Admission Date:  [**2125-2-9**]              D...      Report   \n",
       "1  121936.0  PATIENT/TEST INFORMATION:\\nIndication: Aortic ...      Report   \n",
       "2  121936.0  PATIENT/TEST INFORMATION:\\nIndication:  Aortic...      Report   \n",
       "3  121936.0  Sinus rhythm.  Frequent atrial premature beats...      Report   \n",
       "4  121936.0  Rhythm is most likely sinus rhythm with freque...      Report   \n",
       "\n",
       "            CATEGORY  SUBJECT_ID  \\\n",
       "0  Discharge summary       28063   \n",
       "1               Echo       28063   \n",
       "2               Echo       28063   \n",
       "3                ECG       28063   \n",
       "4                ECG       28063   \n",
       "\n",
       "                                           ICD9_CODE  \\\n",
       "0  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
       "1  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
       "2  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
       "3  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
       "4  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
       "\n",
       "                                   ICD9_CODE_primary  \n",
       "0  [428, 410, 599, 427, 584, 507, 428, 272, 401, ...  \n",
       "1  [428, 410, 599, 427, 584, 507, 428, 272, 401, ...  \n",
       "2  [428, 410, 599, 427, 584, 507, 428, 272, 401, ...  \n",
       "3  [428, 410, 599, 427, 584, 507, 428, 272, 401, ...  \n",
       "4  [428, 410, 599, 427, 584, 507, 428, 272, 401, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combineddf=noteEvents.merge(admissionswithDiabetes, on=\"HADM_ID\")\n",
    "print(combineddf.shape)\n",
    "combineddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b80e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "processeddf=combineddf.copy()\n",
    "spacestring=\" \"*len(string.punctuation.replace(\"'\",\"\"))\n",
    "dstring=\"d\"*len(string.digits)\n",
    "processeddf[\"TEXT\"]=processeddf[\"TEXT\"].apply(lambda x: x.translate(str.maketrans(string.punctuation.replace(\"'\",\"\"),spacestring)))\n",
    "processeddf[\"TEXT\"] = processeddf[\"TEXT\"].apply(lambda x: x.translate(str.maketrans(string.digits,dstring)))\n",
    "processeddf[\"TEXT\"] = processeddf[\"TEXT\"].apply(lambda x: x.lower())\n",
    "processeddf[\"TEXT\"] = processeddf[\"TEXT\"].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3656af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordslist=processeddf[\"TEXT\"].tolist()\n",
    "flatlist=list(itertools.chain(*wordslist))\n",
    "wordset=set(flatlist)\n",
    "wordDict=Counter(flatlist)\n",
    "wordDict5orMore= dict(filter(lambda x: x[1] >=5, wordDict.items())) \n",
    "\n",
    "wordDictLessThan5 = dict(filter(lambda x: x[1] <5, wordDict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32dfb27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53229\n",
      "109486\n"
     ]
    }
   ],
   "source": [
    "print(len(wordDict5orMore)) #53229\n",
    "print(len(wordDictLessThan5)) #109486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74c9cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###GENERATE Dictionary for mapping mispelled words\n",
    "# mapped_dict = dict()\n",
    "\n",
    "# for w in range(len(wordListLessThan5)):\n",
    "#     lev_dist = []\n",
    "#     for i in range(len(wordList5orMore)):\n",
    "#         lev_dist.append(lev(wordListLessThan5[w], wordList5orMore[i]))\n",
    "#     print(np.argmin(lev_dist))\n",
    "#     mapped_dict[wordListLessThan5[w]] = wordList5orMore[np.argmin(lev_dist)]\n",
    "\n",
    "# print(len(mapped_dict))\n",
    "\n",
    "# with open('mapDictionary.pkl', 'wb') as f:\n",
    "#     pickle.dump(mapped_dict, f)\n",
    "\n",
    "with open('mapDictionary.pkl', 'rb') as f:\n",
    "    mapped_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15354c07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399623, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>ICD9_CODE_primary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121936.0</td>\n",
       "      <td>[patient, test, information, indication, aorti...</td>\n",
       "      <td>Report</td>\n",
       "      <td>Echo</td>\n",
       "      <td>28063</td>\n",
       "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
       "      <td>[428, 410, 599, 427, 584, 507, 428, 272, 401, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121936.0</td>\n",
       "      <td>[patient, test, information, indication, aorti...</td>\n",
       "      <td>Report</td>\n",
       "      <td>Echo</td>\n",
       "      <td>28063</td>\n",
       "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
       "      <td>[428, 410, 599, 427, 584, 507, 428, 272, 401, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121936.0</td>\n",
       "      <td>[sinus, rhythm, frequent, atrial, premature, b...</td>\n",
       "      <td>Report</td>\n",
       "      <td>ECG</td>\n",
       "      <td>28063</td>\n",
       "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
       "      <td>[428, 410, 599, 427, 584, 507, 428, 272, 401, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121936.0</td>\n",
       "      <td>[rhythm, is, most, likely, sinus, rhythm, with...</td>\n",
       "      <td>Report</td>\n",
       "      <td>ECG</td>\n",
       "      <td>28063</td>\n",
       "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
       "      <td>[428, 410, 599, 427, 584, 507, 428, 272, 401, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>121936.0</td>\n",
       "      <td>[atrial, fibrillation, intraventricular, condu...</td>\n",
       "      <td>Report</td>\n",
       "      <td>ECG</td>\n",
       "      <td>28063</td>\n",
       "      <td>[42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...</td>\n",
       "      <td>[428, 410, 599, 427, 584, 507, 428, 272, 401, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HADM_ID                                               TEXT DESCRIPTION  \\\n",
       "1  121936.0  [patient, test, information, indication, aorti...      Report   \n",
       "2  121936.0  [patient, test, information, indication, aorti...      Report   \n",
       "3  121936.0  [sinus, rhythm, frequent, atrial, premature, b...      Report   \n",
       "4  121936.0  [rhythm, is, most, likely, sinus, rhythm, with...      Report   \n",
       "5  121936.0  [atrial, fibrillation, intraventricular, condu...      Report   \n",
       "\n",
       "  CATEGORY  SUBJECT_ID                                          ICD9_CODE  \\\n",
       "1     Echo       28063  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
       "2     Echo       28063  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
       "3      ECG       28063  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
       "4      ECG       28063  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
       "5      ECG       28063  [42843, 41071, 5990, 4275, 5849, 5070, 4280, 2...   \n",
       "\n",
       "                                   ICD9_CODE_primary  \n",
       "1  [428, 410, 599, 427, 584, 507, 428, 272, 401, ...  \n",
       "2  [428, 410, 599, 427, 584, 507, 428, 272, 401, ...  \n",
       "3  [428, 410, 599, 427, 584, 507, 428, 272, 401, ...  \n",
       "4  [428, 410, 599, 427, 584, 507, 428, 272, 401, ...  \n",
       "5  [428, 410, 599, 427, 584, 507, 428, 272, 401, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limited_processeddf = processeddf[processeddf['TEXT'].apply(lambda x: len(x)) > 9]\n",
    "limited_processeddf = limited_processeddf[limited_processeddf['TEXT'].apply(lambda x: len(x)) < 2200]\n",
    "print(limited_processeddf.shape)\n",
    "limited_processeddf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db28aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_misspelled(x):\n",
    "    new_l = [mapped_dict.get(item, item) for item in x]\n",
    "    return new_l\n",
    "\n",
    "limited_processeddf[\"TEXT\"] = limited_processeddf[\"TEXT\"].apply(lambda x: map_misspelled(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ac9dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_processeddf[\"ICD9_SET\"]= limited_processeddf[\"ICD9_CODE\"].apply(lambda x: set(x))\n",
    "limited_processeddf[\"ICD9_primary_SET\"]= limited_processeddf[\"ICD9_CODE_primary\"].apply(lambda x: set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ce3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Binary Relevance\n",
    "top_10codes=[\"427\",\"518\",\"428\",\"584\",\"401\",\"276\",\"414\",\"285\",\"272\",\"585\"]\n",
    "def TopCodes(x):\n",
    "    toplist=[]\n",
    "    for topcode in top_10codes:\n",
    "        for code in x:\n",
    "            flag=0\n",
    "            if str(code).startswith(topcode):\n",
    "                flag=1\n",
    "        toplist.append(flag)\n",
    "    return toplist\n",
    "\n",
    "limited_processeddf[\"Top_ICD9_Codes\"]=limited_processeddf[\"ICD9_primary_SET\"].apply(lambda x: TopCodes(x))\n",
    "binarycodes=pd.DataFrame(limited_processeddf[\"Top_ICD9_Codes\"].tolist(),columns=[\"427\",\"518\",\"428\",\"584\",\"401\",\"276\",\"414\",\"285\",\"272\",\"585\"])\n",
    "binarycodes.head()\n",
    "\n",
    "\n",
    "#Filter codes to only top 10 for comparision to Binary relevance\n",
    "def TopCodesList(x):\n",
    "    toplist=[]\n",
    "    for code in x:\n",
    "        if str(code).startswith(tuple(top_10codes)):\n",
    "            toplist.append(code)\n",
    "    return toplist\n",
    "\n",
    "limited_processeddf[\"Top_ICD9_Codes\"]=limited_processeddf[\"ICD9_primary_SET\"].apply(lambda x: TopCodesList(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8ef3776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to CSV\n",
    "#limited_processeddf.to_csv(\"Tokenized.csv\")\n",
    "#binarycodes.to_csv(\"binarycodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4ee911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarycodes=pd.read_csv(\"binarycodes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652f027e",
   "metadata": {},
   "source": [
    "## Preprocessed Data Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1717112e",
   "metadata": {},
   "source": [
    "icd9_list=limited_processeddf[\"ICD9_CODE_primary\"].tolist()\n",
    "icd9_flatlist=list(itertools.chain(*icd9_list))\n",
    "print(\"Num. icd9 primary code\",len(icd9_flatlist))\n",
    "icd9_wordset=set(icd9_flatlist)\n",
    "icd9_wordDict=Counter(icd9_flatlist)\n",
    "print(\"Num. unique icd9 primary code\",len(icd9_wordDict))\n",
    "icd9_re_list=limited_processeddf[\"ICD9_CODE\"].tolist()\n",
    "icd9_re_flatlist=list(itertools.chain(*icd9_re_list))\n",
    "print(\"Num. icd9 regular code\",len(icd9_re_flatlist))\n",
    "icd9_re_wordset=set(icd9_re_flatlist)\n",
    "icd9_re_wordDict=Counter(icd9_re_flatlist)\n",
    "print(\"Num. unique icd9 regular code\",len(icd9_re_wordDict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d3676d",
   "metadata": {},
   "source": [
    "limited_processeddf[\"ICD9_SET\"]= limited_processeddf[\"ICD9_CODE\"].apply(lambda x: set(x))\n",
    "limited_processeddf[\"ICD9_primary_SET\"]= limited_processeddf[\"ICD9_CODE_primary\"].apply(lambda x: set(x))\n",
    "limited_processeddf[\"NumberofICD9Codes\"] = limited_processeddf[\"ICD9_SET\"].apply(lambda x: len(x))\n",
    "limited_processeddf[\"NumberofICD9CodesPri\"] = limited_processeddf[\"ICD9_CODE_primary\"].apply(lambda x: len(set(x)))\n",
    "CodesperReport = limited_processeddf[\"NumberofICD9Codes\"].tolist()\n",
    "avgcodesperReport = sum(CodesperReport) / len(CodesperReport)\n",
    "PriCodesperReportlist = limited_processeddf[\"NumberofICD9CodesPri\"].tolist()\n",
    "avgPriCodesperReport = sum(PriCodesperReportlist) / len(PriCodesperReportlist)\n",
    "print(\"avgCodesperReport\",avgcodesperReport)\n",
    "print(\"avgPriCodesperReport\",avgPriCodesperReport)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8a836d",
   "metadata": {},
   "source": [
    "limited_processeddf[\"NumberofTokens\"] = limited_processeddf[\"TEXT\"].apply(lambda x: len(x))\n",
    "NumberofTokensList=limited_processeddf[\"NumberofTokens\"].tolist()\n",
    "avgTokensperReport = sum(NumberofTokensList) / len(NumberofTokensList)\n",
    "print(\"avgTokensperReport\",avgTokensperReport)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653865bd",
   "metadata": {},
   "source": [
    "print(\"avgDensityperReport\",avgcodesperReport/len(icd9_wordDict))\n",
    "print(\"avgPriDensityperReport\",avgPriCodesperReport/len(icd9_re_wordDict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bab00a7",
   "metadata": {},
   "source": [
    "limited_processeddf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469f554",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5976855",
   "metadata": {},
   "outputs": [],
   "source": [
    "del processeddf,combineddf,admissionswithDiabetes,noteEvents,diagnosis,diagnosisGrouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daab2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import sklearn as sk\n",
    "import string\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn import preprocessing, metrics\n",
    "from keras.layers import Dense, Lambda, Dropout, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Embedding, Activation,Input,concatenate,Flatten\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import multilabel_confusion_matrix, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c066c770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5d3e3",
   "metadata": {},
   "source": [
    "# SET ROLLED UP CODES HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57f29065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399623, 808)\n"
     ]
    }
   ],
   "source": [
    "tokenized=limited_processeddf\n",
    "mlb = preprocessing.MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(tokenized[\"ICD9_CODE_primary\"])\n",
    "y = pd.DataFrame(y)\n",
    "print(y.shape) #full: (399623, 808)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8136887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_evaluation_score(y_true, y_pred):\n",
    "   \n",
    "    # compute true positives across training examples and labels\n",
    "    tp = np.sum(np.logical_and(y_true, y_pred))\n",
    "    \n",
    "    # compute false negatives (Missed Labels) across training examples and labels\n",
    "    fn = np.sum(np.logical_and(y_true, np.logical_not(y_pred)))\n",
    "    \n",
    "    fp = np.sum(np.logical_and(np.logical_not(y_true), y_pred))\n",
    "\n",
    "    # compute False Positive across training examples and labels.\n",
    "    f1 = 2*tp / (2* tp + fp + fn)\n",
    "    \n",
    "    return np.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3eda266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_w2v_model(x_train):\n",
    "    #w2v_model = Word2Vec.load(\"drive/MyDrive/BD4H Project Folder/word2vec.model\")\n",
    "    w2v_model = Word2Vec(x_train, vector_size=300)\n",
    "    #w2v_model.save(\"word2vec_test.model\")\n",
    "    #print(w2v_model)\n",
    "    return w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb6a138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence(w2v_model,x_train,x_val,x_test):\n",
    "    num_unique_tokens = len(w2v_model.wv)\n",
    "    token = Tokenizer(num_unique_tokens)\n",
    "    token.fit_on_texts(x_train)\n",
    "    train_text = token.texts_to_sequences(x_train)\n",
    "    x_train_seq = pad_sequences(train_text)\n",
    "    print(x_train_seq.shape) \n",
    "\n",
    "    sequences_val = token.texts_to_sequences(x_val)\n",
    "    x_val_seq = pad_sequences(sequences_val, maxlen=x_train_seq.shape[1]) \n",
    "    print(x_val_seq.shape)\n",
    "\n",
    "    sequences_test = token.texts_to_sequences(x_test)\n",
    "    x_test_seq = pad_sequences(sequences_test, maxlen=x_train_seq.shape[1]) \n",
    "    print(x_test_seq.shape)\n",
    "\n",
    "    return x_train_seq,x_val_seq,x_test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6480cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_vector(w2v_model):\n",
    "\n",
    "    num_unique_tokens = len(w2v_model.wv)\n",
    "    token = Tokenizer(num_unique_tokens)\n",
    "    embeddings_index = {}\n",
    "    for w in w2v_model.wv.key_to_index:\n",
    "        idx=w2v_model.wv.key_to_index[w]\n",
    "        embeddings_index[idx] = w2v_model.wv[idx]\n",
    "\n",
    "    num_words = num_unique_tokens\n",
    "    embedding_matrix = np.zeros((num_words, 300))\n",
    "    for word, i in token.word_index.items():\n",
    "        if i >= num_words:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b981976",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=5024)])\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "381fbd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(dim):\n",
    "\t# define our MLP network\n",
    "\tcat_model = Sequential()\n",
    "\tcat_model.add(Dense(128, input_dim=dim, activation=\"relu\"))\n",
    "\tcat_model.add(Dense(64, activation=\"relu\"))\n",
    "\treturn cat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f118fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BOT_base_test(x_train_seq,y_train,x_val_seq,y_val,x_test_seq,y_test,num_unique_tokens):\n",
    "    report_input = Input(shape=(x_train_seq.shape[1],), dtype='int32')\n",
    "\n",
    "    report_encoder = Embedding(num_unique_tokens, 300, input_length=x_train_seq.shape[1], trainable=True)(report_input)\n",
    "    report_encoder_mean = Lambda(lambda x: tf.reduce_mean(x, axis=1, keepdims=True))(report_encoder)\n",
    "    bigram_branch = Dense(y_train.shape[1])(report_encoder_mean)\n",
    "    bigram_branch = GlobalMaxPooling1D()(report_encoder_mean)\n",
    "\n",
    "    merged = Dense(y_train.shape[1])(bigram_branch)\n",
    "\n",
    "    output = Activation('sigmoid')(merged)\n",
    "\n",
    "    model = Model(inputs=[report_input], outputs=[output])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11fb1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_3dense(mlp,cnn,cat_train,cat_val,cat_test,x_train_seq,y_train,x_val_seq,y_val,x_test_seq,y_test):\n",
    "    combinedInput = concatenate([mlp.output, cnn.output])\n",
    "    \n",
    "    #Add/Remove Dense Layers Here:\n",
    "    \n",
    "    combinedInput = Dense(64, activation=\"relu\")(combinedInput)\n",
    "    #combinedInput = Dense(64, activation=\"relu\")(combinedInput)\n",
    "    combinedInput = Dense(64, activation=\"relu\")(combinedInput)\n",
    "    \n",
    "    combinedOutput = Dense(y_train.shape[1], activation=\"sigmoid\")(combinedInput)\n",
    "    model = Model(inputs=[mlp.input, cnn.input], outputs=combinedOutput)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), loss=tf.keras.losses.BinaryCrossentropy())\n",
    "    \n",
    "    callbacks = [EarlyStopping(min_delta=0.0001,patience=2)]\n",
    "    model.fit([cat_train, x_train_seq], y_train, validation_data=([cat_val, x_val_seq], y_val),callbacks=callbacks,batch_size=32, epochs=2)\n",
    "\n",
    "    yhat_cnn = model.predict([cat_test, x_test_seq])\n",
    "    yhat_cnn[yhat_cnn>0.5] = 1\n",
    "    yhat_cnn[yhat_cnn<=0.5] = 0\n",
    "    yhat_cnn = pd.DataFrame(yhat_cnn,dtype=int)\n",
    "\n",
    "    precision = precision_score(y_test, yhat_cnn,average=\"micro\")\n",
    "    recall = recall_score(y_test, yhat_cnn,average=\"micro\")\n",
    "    f1 = f1_score(y_test, yhat_cnn, average=\"micro\")\n",
    "    return  precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c63b5701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5004a5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399623, 15)\n"
     ]
    }
   ],
   "source": [
    "ohe = preprocessing.OneHotEncoder()\n",
    "cats = ohe.fit_transform(tokenized[[\"CATEGORY\"]]).toarray()\n",
    "print(cats.shape)\n",
    "cats = pd.DataFrame(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a50a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenized=tokenized[[\"TEXT\"]]\n",
    "def runBOTbase():    \n",
    "\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 2)\n",
    "    precision_list_re = []\n",
    "    recall_list_re = []\n",
    "    f1_list_re = []\n",
    "\n",
    "    for train_index, test_index in kf.split(tokenized):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        x_train, x_test = tokenized[\"TEXT\"].iloc[train_index], tokenized[\"TEXT\"].iloc[test_index]\n",
    "        y_train_regular,y_test_regular = y.iloc[train_index],y.iloc[test_index]\n",
    "        cat_train,cat_test =cats.iloc[train_index], cats.iloc[test_index]\n",
    "        x_val = x_train.sample(frac=0.1,random_state=42)\n",
    "        y_val_regular = y_train_regular.sample(frac=0.1,random_state=42)\n",
    "        cat_val = cat_train.sample(frac=0.1,random_state=42)\n",
    "\n",
    "        w2v_model = build_w2v_model(x_train)\n",
    "        num_unique_tokens = len(w2v_model.wv)\n",
    "        x_train_seq,x_val_seq,x_test_seq = get_sequence(w2v_model,x_train,x_val,x_test)\n",
    "        embedding_matrix = build_embedding_vector(w2v_model)\n",
    "        mlp = create_mlp(cat_train.shape[1])\n",
    "\n",
    "        BOT_base = BOT_base_test(x_train_seq,y_train_regular,x_val_seq,y_val_regular,x_test_seq,y_test_regular,num_unique_tokens)\n",
    "        \n",
    "        precision, recall, f1 = concatenate_3dense(mlp,BOT_base,cat_train,cat_val,cat_test,x_train_seq,y_train_regular,x_val_seq,y_val_regular,x_test_seq,y_test_regular)\n",
    "\n",
    "        print(precision, recall, f1)\n",
    "        precision_list_re.append(precision)\n",
    "        recall_list_re.append(recall)\n",
    "        f1_list_re.append(f1)\n",
    "        tf.keras.backend.clear_session()\n",
    "    \n",
    "    print(np.mean(precision_list_re))\n",
    "    print(np.mean(recall_list_re))\n",
    "    print(np.mean(f1_list_re))\n",
    "\n",
    "\n",
    "        \n",
    "runBOTbase()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd250f2",
   "metadata": {},
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aacdeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset Tokenized if running samples\n",
    "tokenized=limited_processeddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecba95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9fa7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
